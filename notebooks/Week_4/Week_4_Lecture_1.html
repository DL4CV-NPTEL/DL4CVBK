
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lecture 1 : Neural Networks: A Review Part 1 Code &#8212; Deep Learning For Computer Vision</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Lecture 2: Neural Networks: A Review Part 2 Code" href="Week_4_Lecture_2.html" />
    <link rel="prev" title="Week 4" href="Week_4.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/IITH_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning For Computer Vision</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to the Course
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Prereq.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_1/Week_1.html">
   Week 1
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_1.html">
     Lecture 1: Course Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_2.html">
     Lecture 2: History
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_3.html">
     Lecture 3: Image Formation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_4.html">
     Lecture 4: Image Representation
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_5.html">
     Lecture 5: Linear Filtering, Correlation, Convolution
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_6.html">
     Lecture 6: Image in Frequency Domain
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_1/Week_1_Lecture_7.html">
     Lecture 7: Image Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_2/Week_2.html">
   Week 2
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_1.html">
     Lecture 1: Edge Detection
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_2.html">
     Lecture 2: From Edges to Blobs and Corners
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_3.html">
     Lecture 3: Scale Space, Image Pyramids and Filter Banks
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_4.html">
     Lecture 4: SIFT and Variants
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_5.html">
     Lecture 5: Image Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_6.html">
     Lecture 6: Other Feature Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_2/Week_2_Lecture_7.html">
     Lecture 7: Human Visual System
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_3/Week_3.html">
   Week 3
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_3/Week_3_Lecture_1.html">
     Lecture 1: Feature Matching
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_3/Week_3_Lecture_2.html">
     Lecture 2: Hough Transform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_3/Week_3_Lecture_3.html">
     Lecture 3: From Points to Images: Bag-of-Words and VLAD Representations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_3/Week_3_Lecture_4.html">
     Lecture 4: Image Descriptor Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_3/Week_3_Lecture_5.html">
     Lecture 5: Pyramid Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_3/Week_3_Lecture_6.html">
     Lecture 6: From Traditional Vision to Deep Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Week_4.html">
   Week 4
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Lecture 1 : Neural Networks: A Review Part 1
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_2.html">
     Lecture 2: Neural Networks: A Review Part 2
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_3.html">
     Lecture 3: Feedforward Neural Networks and Backpropagation Part 1
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_4.html">
     Lecture 4: Feedforward Neural Networks and Backpropagation Part 2
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_5.html">
     Lecture 5: Gradient Descent and Variants Part 1
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_6.html">
     Lecture 6: Gradient Descent and Variants Part 2
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_7.html">
     Lecture 7: Regularization in Neural Networks Part 1
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_8.html">
     Lecture 8: Regularization in Neural Networks Part 2
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_9.html">
     Lecture 9: Improving Training of Neural Networks Part 1
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week_4_Lecture_10.html">
     Lecture 10: Improving Training of Neural Networks Part 2
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_5/Week_5.html">
   Week 5
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_1.html">
     Lecture 1: Convolutional Neural Networks: An Introduction - Part 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_2.html">
     Lecture 2: Convolutional Neural Networks: An Introduction - Part 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_3.html">
     Lecture 3: Backpropagation in CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_4.html">
     Lecture 4: Evolution of CNN Architectures for Image Classification - Part01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_5.html">
     Lecture 5: Evolution of CNN Architectures for Image Classification - Part02
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_6.html">
     Lecture 6: Recent CNN Architectures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_5/Week_5_Lecture_7.html">
     Lecture 7: Finetuning in CNNs
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_6/Week_6.html">
   Week 6
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_6/Week_6_Lecture_1.html">
     Lecture 1: Explaining CNNs: Visualization Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_6/Week_6_Lecture_2.html">
     Lecture 2: Explaining CNNs: Early Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_6/Week_6_Lecture_3.html">
     Lecture 3: Explaining CNNs: Class Attribution Map Methods
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_6/Week_6_Lecture_4.html">
     Lecture 4: Explaining CNNs: Recent Methods - Part 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_6/Week_6_Lecture_5.html">
     Lecture 5: Explaining CNNs: Recent Methods - Part 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_6/Week_6_Lecture_6.html">
     Lecture 6: Going Beyond Explaining CNNs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_7/Week_7.html">
   Week 7
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_1.html">
     Lecture 1: CNNs for Object Detection-I - Part 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_2.html">
     Lecture 2: CNNs for Object Detection-I - Part 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_3.html">
     Lecture 3: CNNs for Object Detection-II
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_4.html">
     Lecture 4: CNNs for Segmentation
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_5.html">
     Lecture 5: CNNs for Human Understanding: Faces -Part 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_6.html">
     Lecture 6: CNNs for Human Understanding: Faces -Part 02
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_7.html">
     Lecture 7: CNNs for Human Understanding: Human Pose and Crowd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_7/Week_7_Lecture_8.html">
     Lecture 8: CNNs for Other Image Tasks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_8/Week_8.html">
   Week 8
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_8/Week_8_Lecture_1.html">
     Lecture 1: Recurrent Neural Networks: Introduction
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_8/Week_8_Lecture_2.html">
     Lecture 2: Backpropagation in RNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_8/Week_8_Lecture_3.html">
     Lecture 3: LSTMs and GRUs
     <sup>
      <mark style="background-color:gold">
       Code
      </mark>
     </sup>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_8/Week_8_Lecture_4.html">
     Lecture 4: Video Understanding using CNNs and RNNs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_9/Week_9.html">
   Week 9
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_9/Week_9_Lecture_1.html">
     Lecture 1: Attention in Vision Models: An Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_9/Week_9_Lecture_2.html">
     Lecture 2: Vision and Language: Image Captioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_9/Week_9_Lecture_3.html">
     Lecture 3: Beyond Captioning: Visual QA, Visual Dialog
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_9/Week_9_Lecture_4.html">
     Lecture 4: Other Attention Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_9/Week_9_Lecture_5.html">
     Lecture 5: Self-Attention and Transformers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_10/Week_10.html">
   Week 10
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_1.html">
     Lecture 10: Deep Generative Models: An Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_2.html">
     Lecture 2: Generative Adversarial Networks - Part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_3.html">
     Lecture 3: Generative Adversarial Networks - Part 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_4.html">
     Lecture 4: Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_5.html">
     Lecture 5: Combining VAEs and GANs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_6.html">
     Lecture 6: Beyond VAEs and GANs: Other Deep Generative Models - Part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_10/Week_10_Lecture_7.html">
     Lecture 7 : Beyond VAEs and GANs: Other Deep Generative Models - Part 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_11/Week_11.html">
   Week 11
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_11/Week_11_Lecture_1.html">
     Lecture 1 : GAN Improvements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_11/Week_11_Lecture_2.html">
     Lecture 2: Deep Generative Models across Multiple Domains
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_11/Week_11_Lecture_3.html">
     Lecture 3: VAEs and Disentanglement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_11/Week_11_Lecture_4.html">
     Lecture 4: Deep Generative Models: Image Applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_11/Week_11_Lecture_5.html">
     Lecture 5: Deep Generative Models: Video Applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week_12/Week_12.html">
   Week 12
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_1.html">
     Lecture 1: Few-shot and Zero-shot Learning - Part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_2.html">
     Lecture 2: Few-shot and Zero-shot Learning - Part 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_3.html">
     Lecture 3: Self-Supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_4.html">
     Lecture 4: Adversarial Robustness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_5.html">
     Lecture 5: Pruning and Model Compression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_6.html">
     Lecture 6: Neural Architecture Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week_12/Week_12_Lecture_7.html">
     Lecture 7 : Course Conclusion
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/notebooks/Week_4/Week_4_Lecture_1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fnotebooks/Week_4/Week_4_Lecture_1.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/notebooks/Week_4/Week_4_Lecture_1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-basics-of-pytorch">
   The Basics of PyTorch
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-tensors">
     Creating Tensors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operations-in-pytorch">
     Operations in PyTorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manipulating-tensors-in-pytorch">
     Manipulating Tensors in Pytorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gpus">
     GPUs
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lecture 1 : Neural Networks: A Review Part 1 <sup><mark style="background-color:gold">Code</mark> </sup></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-basics-of-pytorch">
   The Basics of PyTorch
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-tensors">
     Creating Tensors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operations-in-pytorch">
     Operations in PyTorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manipulating-tensors-in-pytorch">
     Manipulating Tensors in Pytorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gpus">
     GPUs
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><a href="https://colab.research.google.com/github/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/notebooks/Week_4/Week_4_Lecture_1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="lecture-1-neural-networks-a-review-part-1-sup-mark-style-background-color-gold-code-mark-sup">
<h1>Lecture 1 : Neural Networks: A Review Part 1 <sup><mark style="background-color:gold">Code</mark> </sup><a class="headerlink" href="#lecture-1-neural-networks-a-review-part-1-sup-mark-style-background-color-gold-code-mark-sup" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title </span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>
<span class="n">out1</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
<span class="k">with</span> <span class="n">out1</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
  <span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;47d0M3UAXNc&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
  <span class="n">display</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2918dffb7eb248bb8c8af1ac357a4d8e"}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title </span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPyDisplay</span>
<span class="n">IPyDisplay</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">  &lt;div&gt;</span>
<span class="s2">    &lt;a href= &quot;https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Slides/Week_4/DL4CV_Week04_Part01.pdf&quot; target=&quot;_blank&quot;&gt;</span>
<span class="s2">    &lt;img src=&quot;https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Data/Slides_Logo.png?raw=1&quot;</span>
<span class="s2">  alt=&quot;button link to Airtable&quot; style=&quot;width:200px&quot;&gt;&lt;/a&gt;</span>
<span class="s2">    &lt;/div&gt;&quot;&quot;&quot;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
  <a href= "https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Slides/Week_4/DL4CV_Week04_Part01.pdf" target="_blank">
  <img src="https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Data/Slides_Logo.png?raw=1"
alt="button link to Airtable" style="width:200px"></a>
  </div></div></div>
</div>
<p><strong>Imports</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># PyTorch libraries</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
</pre></div>
</div>
</div>
</div>
<section id="the-basics-of-pytorch">
<h2>The Basics of PyTorch<a class="headerlink" href="#the-basics-of-pytorch" title="Permalink to this headline">#</a></h2>
<p>PyTorch is a Python-based scientific computing package targeted at two sets of
audiences:</p>
<ul class="simple">
<li><p>A replacement for NumPy optimized for the power of GPUs</p></li>
<li><p>A deep learning platform that provides significant flexibility
and speed</p></li>
</ul>
<p>At its core, PyTorch provides a few key features:</p>
<ul class="simple">
<li><p>A multidimensional <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html">Tensor</a> object, similar to <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html">NumPy Array</a> but with GPU acceleration.</p></li>
<li><p>An optimized <strong>autograd</strong> engine for automatically computing derivatives.</p></li>
<li><p>A clean, modular API for building and deploying <strong>deep learning models</strong>.</p></li>
</ul>
<p>You can find more information about PyTorch in the Appendix.</p>
<section id="creating-tensors">
<h3>Creating Tensors<a class="headerlink" href="#creating-tensors" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can construct a tensor directly from some common python iterables,</span>
<span class="c1"># such as list and tuple nested iterables can also be handled as long as the</span>
<span class="c1"># dimensions are compatible</span>

<span class="c1"># tensor from a list</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="c1">#tensor from a tuple of tuples</span>
<span class="n">b</span> <span class="o">=</span> <span class="p">((</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="c1"># tensor from a numpy array</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor a: </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor b: </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor c: </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tensor a: tensor([0, 1, 2])
Tensor b: tensor([[1.0000, 1.1000],
        [1.2000, 1.3000]])
Tensor c: tensor([[1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<p><strong>Some common tensor constructors:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The numerical arguments we pass to these constructors</span>
<span class="c1"># determine the shape of the output tensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor x: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor y: </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor z: </span><span class="si">{</span><span class="n">z</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tensor x: tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
Tensor y: tensor([0., 0.])
Tensor z: tensor([[[1.7433e-35, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan]]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># There are also constructors for random numbers</span>

<span class="c1"># Uniform distribution</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Normal distribution</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># There are also constructors that allow us to construct</span>
<span class="c1"># a tensor according to the above constructors, but with</span>
<span class="c1"># dimensions equal to another tensor.</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor a: </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor b: </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor c: </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor d: </span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tensor a: tensor([[0.3057, 0.2544, 0.9737]])
Tensor b: tensor([[ 1.7424, -0.7077, -0.7339, -0.0538],
        [-0.5136, -0.7716,  0.0846,  0.6274],
        [-0.5731,  0.4269, -2.5037,  0.6730]])
Tensor c: tensor([[0., 0., 0.]])
Tensor d: tensor([[0.5056, 0.3271, 0.4315]])
</pre></div>
</div>
</div>
</div>
<p><em>Reproducibility</em>:</p>
<ul class="simple">
<li><p>PyTorch Random Number Generator (RNG): You can use <code class="docutils literal notranslate"><span class="pre">torch.manual_seed()</span></code> to seed the RNG for all devices (both CPU and GPU):</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>For custom operators, you might need to set python seed as well:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Random number generators in other libraries (e.g., NumPy):</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we define for you a function called <code class="docutils literal notranslate"><span class="pre">set_seed</span></code> that does the job for you!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Function that controls randomness. NumPy and random modules must be imported.</span>

<span class="sd">  Args:</span>
<span class="sd">    seed : Integer</span>
<span class="sd">      A non-negative integer that defines the random state. Default is `None`.</span>
<span class="sd">    seed_torch : Boolean</span>
<span class="sd">      If `True` sets the random seed for pytorch tensors, so pytorch module</span>
<span class="sd">      must be imported. Default is `True`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s use the <code class="docutils literal notranslate"><span class="pre">set_seed</span></code> function in the previous example. Execute the cell multiple times to verify that the numbers printed are always the same.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simplefun</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">my_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Helper function to verify effectiveness of set_seed attribute</span>

<span class="sd">  Args:</span>
<span class="sd">    seed: Boolean</span>
<span class="sd">      Specifies if seed value is provided or not</span>
<span class="sd">    my_seed: Integer</span>
<span class="sd">      Initializes seed to specified value</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">seed</span><span class="p">:</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">my_seed</span><span class="p">)</span>

  <span class="c1"># uniform distribution</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
  <span class="c1"># normal distribution</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor a: &quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor b: &quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simplefun</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">my_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Turn `seed` to `False` or change `my_seed`</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 0 has been set.
Tensor a:  tensor([[0.4963, 0.7682, 0.0885]])
Tensor b:  tensor([[ 0.3643,  0.1344,  0.1642,  0.3058],
        [ 0.2100,  0.9056,  0.6035,  0.8110],
        [-0.0451,  0.8797,  1.0482, -0.0445]])
</pre></div>
</div>
</div>
</div>
<p><strong>Numpy-like number ranges:</strong></p>
<p>The <code class="docutils literal notranslate"><span class="pre">.arange()</span></code> and <code class="docutils literal notranslate"><span class="pre">.linspace()</span></code> behave how you would expect them to if you are familar with numpy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor a: </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Numpy array b: </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor c: </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Numpy array d: </span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tensor a: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

Numpy array b: [0 1 2 3 4 5 6 7 8 9]

Tensor c: tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,
        4.5000, 5.0000])

Numpy array d: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="operations-in-pytorch">
<h3>Operations in PyTorch<a class="headerlink" href="#operations-in-pytorch" title="Permalink to this headline">#</a></h3>
<p><strong>Tensor-Tensor operations</strong></p>
<p>We can perform operations on tensors using methods under <code class="docutils literal notranslate"><span class="pre">torch.</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># this only works if c and d already exist</span>
<span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>

<span class="c1"># Pointwise Multiplication of a and b</span>
<span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1.0362, 1.1852, 1.3734],
        [1.3051, 1.9320, 1.1759],
        [1.2698, 1.1507, 1.0317],
        [1.2081, 1.9298, 1.7231],
        [1.7423, 1.5263, 1.2437]])
tensor([[0.0362, 0.1852, 0.3734],
        [0.3051, 0.9320, 0.1759],
        [0.2698, 0.1507, 0.0317],
        [0.2081, 0.9298, 0.7231],
        [0.7423, 0.5263, 0.2437]])
</pre></div>
</div>
</div>
</div>
<p>However, in PyTorch, most common Python operators are overridden.
The common standard arithmetic operators (<span class="math notranslate nohighlight">\(+\)</span>, <span class="math notranslate nohighlight">\(-\)</span>, <span class="math notranslate nohighlight">\(*\)</span>, <span class="math notranslate nohighlight">\(/\)</span>, and <span class="math notranslate nohighlight">\(**\)</span>) have all been lifted to elementwise operations</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">/</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="n">y</span>  <span class="c1"># The `**` is the exponentiation operator</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([ 2,  4,  7, 12]),
 tensor([0, 0, 1, 4]),
 tensor([ 1,  4, 12, 32]),
 tensor([1.0000, 1.0000, 1.3333, 2.0000]),
 tensor([   1,    4,   64, 4096]))
</pre></div>
</div>
</div>
</div>
<p><strong>Tensor Methods</strong></p>
<p>Tensors also have a number of common arithmetic operations built in.</p>
<p>All of these operations should have similar syntax to their numpy equivalents.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># sum() - note the axis is the axis you move across when summing</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of every element of x: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of the columns of x: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of the rows of x: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean value of all elements of x </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean values of the columns of x </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean values of the rows of x </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.5846, 0.0332, 0.1387],
        [0.2422, 0.8155, 0.7932],
        [0.2783, 0.4820, 0.8198]])


Sum of every element of x: 4.187318325042725
Sum of the columns of x: tensor([1.1051, 1.3306, 1.7517])
Sum of the rows of x: tensor([0.7565, 1.8509, 1.5800])


Mean value of all elements of x 0.46525758504867554
Mean values of the columns of x tensor([0.3684, 0.4435, 0.5839])
Mean values of the rows of x tensor([0.2522, 0.6170, 0.5267])
</pre></div>
</div>
</div>
</div>
<p><strong>Matrix Operations</strong></p>
<p>The <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> symbol is overridden to represent matrix multiplication. You can also use <code class="docutils literal notranslate"><span class="pre">torch.matmul()</span></code> to multiply tensors. For dot multiplication, you can use <code class="docutils literal notranslate"><span class="pre">torch.dot()</span></code>, or manipulate the axes of your tensors and do matrix multiplication (we will cover that in the next section).</p>
<p>Transposes of 2D tensors are obtained using <code class="docutils literal notranslate"><span class="pre">torch.t()</span></code> or <code class="docutils literal notranslate"><span class="pre">Tensor.T</span></code>. Note the lack of brackets for <code class="docutils literal notranslate"><span class="pre">Tensor.T</span></code> - it is an attribute, not a method.</p>
<p>Below are two expressions involving operations on matrices.</p>
<p>\begin{equation}
\textbf{A} =
\begin{bmatrix}2 &amp;4 \5 &amp; 7
\end{bmatrix}
\begin{bmatrix} 1 &amp;1 \2 &amp; 3
\end{bmatrix}
+
\begin{bmatrix}10 &amp; 10  \ 12 &amp; 1
\end{bmatrix}
\end{equation}</p>
<p>and</p>
<p>\begin{equation}
b =
\begin{bmatrix} 3 \ 5 \ 7
\end{bmatrix} \cdot
\begin{bmatrix} 2 \ 4 \ 8
\end{bmatrix}
\end{equation}</p>
<p>The code block below that computes these expressions using PyTorch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simple_operations</span><span class="p">(</span><span class="n">a1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">a2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">a3</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Helper function to demonstrate simple operations</span>
<span class="sd">  i.e., Multiplication of tensor a1 with tensor a2 and then add it with tensor a3</span>

<span class="sd">  Args:</span>
<span class="sd">    a1: Torch tensor</span>
<span class="sd">      Tensor of size ([2,2])</span>
<span class="sd">    a2: Torch tensor</span>
<span class="sd">      Tensor of size ([2,2])</span>
<span class="sd">    a3: Torch tensor</span>
<span class="sd">      Tensor of size ([2,2])</span>

<span class="sd">  Returns:</span>
<span class="sd">    answer: Torch tensor</span>
<span class="sd">      Tensor of size ([2,2]) resulting from a1 multiplied with a2, added with a3</span>
<span class="sd">  &quot;&quot;&quot;</span>

  
  <span class="n">result</span> <span class="o">=</span>  <span class="n">a1</span> <span class="o">@</span> <span class="n">a2</span> <span class="o">+</span> <span class="n">a3</span>
  <span class="k">return</span> <span class="n">result</span>


<span class="c1"># init our tensors</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">a3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">simple_operations</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">a3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[20, 24],
        [31, 27]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dot_product</span><span class="p">(</span><span class="n">b1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Helper function to demonstrate dot product operation</span>
<span class="sd">  Dot product is an algebraic operation that takes two equal-length sequences</span>
<span class="sd">  (usually coordinate vectors), and returns a single number.</span>
<span class="sd">  Geometrically, it is the product of the Euclidean magnitudes of the</span>
<span class="sd">  two vectors and the cosine of the angle between them.</span>

<span class="sd">  Args:</span>
<span class="sd">    b1: Torch tensor</span>
<span class="sd">      Tensor of size ([3])</span>
<span class="sd">    b2: Torch tensor</span>
<span class="sd">      Tensor of size ([3])</span>

<span class="sd">  Returns:</span>
<span class="sd">    product: Tensor</span>
<span class="sd">      Tensor of size ([1]) resulting from b1 scalar multiplied with b2</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Use torch.dot() to compute the dot product of two tensors</span>
  <span class="n">product</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">product</span>

<span class="n">b1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">dot_product</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(82)
</pre></div>
</div>
</div>
</div>
</section>
<section id="manipulating-tensors-in-pytorch">
<h3>Manipulating Tensors in Pytorch<a class="headerlink" href="#manipulating-tensors-in-pytorch" title="Permalink to this headline">#</a></h3>
<p><strong>Indexing</strong></p>
<p>Just as in numpy, elements in a tensor can be accessed by index. As in any numpy array, the first element has index 0 and ranges are specified to include the first to last_element-1. We can access elements according to their relative position to the end of the list by using negative indices. Indexing is also referred to as slicing.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">[-1]</span></code> selects the last element; <code class="docutils literal notranslate"><span class="pre">[1:3]</span></code> selects the second and the third elements, and <code class="docutils literal notranslate"><span class="pre">[:-2]</span></code> will select all elements excluding the last and second-to-last elements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
tensor(9)
tensor([1, 2])
tensor([0, 1, 2, 3, 4, 5, 6, 7])
</pre></div>
</div>
</div>
</div>
<p>When we have multidimensional tensors, indexing rules work the same way as NumPy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make a 5D tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; shape of x[0]:</span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; shape of x[0][0]:</span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; shape of x[0][0][0]:</span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> shape of x[0]:torch.Size([2, 3, 4, 5])
 shape of x[0][0]:torch.Size([3, 4, 5])
 shape of x[0][0][0]:torch.Size([4, 5])
</pre></div>
</div>
</div>
</div>
<p><strong>Flatten and reshape</strong></p>
<p>There are various methods for reshaping tensors. It is common to have to express 2D data in 1D format. Similarly, it is also common to have to reshape a 1D tensor into a 2D tensor. We can achieve this with the <code class="docutils literal notranslate"><span class="pre">.flatten()</span></code> and <code class="docutils literal notranslate"><span class="pre">.reshape()</span></code> methods.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original z: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">z</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 2D -&gt; 1D</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Flattened z: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">z</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># and back to 2D</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reshaped (3x4) z: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">z</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original z: 
 tensor([[ 0,  1],
        [ 2,  3],
        [ 4,  5],
        [ 6,  7],
        [ 8,  9],
        [10, 11]])
Flattened z: 
 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
Reshaped (3x4) z: 
 tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
</pre></div>
</div>
</div>
</div>
<p>You will also see the <code class="docutils literal notranslate"><span class="pre">.view()</span></code> methods used a lot to reshape tensors. There is a subtle difference between <code class="docutils literal notranslate"><span class="pre">.view()</span></code> and <code class="docutils literal notranslate"><span class="pre">.reshape()</span></code>, though for now we will just use <code class="docutils literal notranslate"><span class="pre">.reshape()</span></code>.</p>
<p><strong>Squeezing tensors</strong></p>
<p>When processing batches of data, you will quite often be left with singleton dimensions. E.g., <code class="docutils literal notranslate"><span class="pre">[1,10]</span></code> or <code class="docutils literal notranslate"><span class="pre">[256,</span> <span class="pre">1,</span> <span class="pre">3]</span></code>. This dimension can quite easily mess up your matrix operations if you don’t plan on it being there…</p>
<p>In order to compress tensors along their singleton dimensions we can use the <code class="docutils literal notranslate"><span class="pre">.squeeze()</span></code> method. We can use the <code class="docutils literal notranslate"><span class="pre">.unsqueeze()</span></code> method to do the opposite.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># printing the zeroth element of the tensor will not give us the first number!</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x[0]: </span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 10])
x[0]: tensor([-0.7391,  0.8027, -0.6817, -0.1335,  0.0658, -0.5919,  0.7670,  0.6899,
         0.3282,  0.5085])
</pre></div>
</div>
</div>
</div>
<p>Because of that pesky singleton dimension, <code class="docutils literal notranslate"><span class="pre">x[0]</span></code> gave us the first row instead!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s get rid of that singleton dimension and see what happens now</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x[0]: </span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([10])
x[0]: -0.7390837073326111
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Adding singleton dimensions works a similar way, and is often used when tensors</span>
<span class="c1"># being added need same number of dimensions</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of y: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># lets insert a singleton dimension</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of y: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of y: torch.Size([5, 5])
Shape of y: torch.Size([5, 1, 5])
</pre></div>
</div>
</div>
</div>
<p><strong>Permutation</strong></p>
<p>Sometimes our dimensions will be in the wrong order! For example, we may be dealing with RGB images with dim <span class="math notranslate nohighlight">\([3\times48\times64]\)</span>, but our pipeline expects the colour dimension to be the last dimension, i.e., <span class="math notranslate nohighlight">\([48\times64\times3]\)</span>. To get around this we can use the <code class="docutils literal notranslate"><span class="pre">.permute()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `x` has dimensions [color,image_height,image_width]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="c1"># We want to permute our tensor to be [ image_height , image_width , color ]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1"># permute(1,2,0) means:</span>
<span class="c1"># The 0th dim of my new tensor = the 1st dim of my old tensor</span>
<span class="c1"># The 1st dim of my new tensor = the 2nd</span>
<span class="c1"># The 2nd dim of my new tensor = the 0th</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([48, 64, 3])
</pre></div>
</div>
</div>
</div>
<p>You may also see <code class="docutils literal notranslate"><span class="pre">.transpose()</span></code> used. This works in a similar way as permute, but can only swap two dimensions at once.</p>
<p><strong>Concatenation</strong></p>
<p>In this example, we concatenate two matrices along rows (axis 0, the first element of the shape) vs. columns (axis 1, the second element of the shape). We can see that the first output tensor’s axis-0 length (<code class="docutils literal notranslate"><span class="pre">6</span></code>) is the sum of the two input tensors’ axis-0 lengths (<code class="docutils literal notranslate"><span class="pre">3+3</span></code>); while the second output tensor’s axis-1 length (<code class="docutils literal notranslate"><span class="pre">8</span></code>) is the sum of the two input tensors’ axis-1 lengths (<code class="docutils literal notranslate"><span class="pre">4+4</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create two tensors of the same shape</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>


<span class="c1"># Concatenate along rows</span>
<span class="n">cat_rows</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Concatenate along columns</span>
<span class="n">cat_cols</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Printing outputs</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Concatenated by rows: shape</span><span class="si">{}</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">cat_rows</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">cat_rows</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> Concatenated by colums: shape</span><span class="si">{}</span><span class="s1">  </span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">cat_cols</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">cat_cols</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Concatenated by rows: shape[6, 4] 
 tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.],
        [ 2.,  1.,  4.,  3.],
        [ 1.,  2.,  3.,  4.],
        [ 4.,  3.,  2.,  1.]])

 Concatenated by colums: shape[3, 8]  
 tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])
</pre></div>
</div>
</div>
</div>
<p><strong>Conversion to Other Python Objects</strong></p>
<p>Converting a tensor to a numpy.ndarray, or vice versa, is easy, and the converted result does not share memory. This minor inconvenience is quite important: when you perform operations on the CPU or GPUs, you do not want to halt computation, waiting to see whether the NumPy package of Python might want to be doing something else with the same chunk of memory.</p>
<p>When converting to a NumPy array, the information being tracked by the tensor will be lost, i.e., the computational graph. This will be covered in detail when you are introduced to autograd tomorrow!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">  |  x type:  </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y: </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2">  |  y type:  </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;z: </span><span class="si">{</span><span class="n">z</span><span class="si">}</span><span class="s2">  |  z type:  </span><span class="si">{</span><span class="n">z</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: tensor([ 0.2659, -0.5148, -0.0613,  0.5046,  0.1385])  |  x type:  torch.FloatTensor
y: [ 0.26593232 -0.5148316  -0.06128114  0.5046449   0.13848118]  |  y type:  &lt;class &#39;numpy.ndarray&#39;&gt;
z: tensor([ 0.2659, -0.5148, -0.0613,  0.5046,  0.1385])  |  z type:  torch.FloatTensor
</pre></div>
</div>
</div>
</div>
<p>To convert a size-1 tensor to a Python scalar, we can invoke the item function or Python’s built-in functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.5</span><span class="p">])</span>
<span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([3.5000]), 3.5, 3.5, 3)
</pre></div>
</div>
</div>
</div>
</section>
<section id="gpus">
<h3>GPUs<a class="headerlink" href="#gpus" title="Permalink to this headline">#</a></h3>
<p>By default, when we create a tensor it will <em>not</em> live on the GPU!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cpu
</pre></div>
</div>
</div>
</div>
<p>When using Colab notebooks, by default, will not have access to a GPU. In order to start using GPUs we need to request one. We can do this by going to the runtime tab at the top of the page.</p>
<p>By following <em>Runtime</em> → <em>Change runtime type</em> and selecting <strong>GPU</strong> from the <em>Hardware Accelerator</em> dropdown list, we can start playing with sending tensors to GPUs.</p>
<p>Once you have done this your runtime will restart and you will need to rerun the first setup cell to reimport PyTorch. Then proceed to the next cell.</p>
<p><strong>Now we have a GPU.</strong></p>
<p>The cell below should return <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://developer.nvidia.com/cuda-toolkit">CUDA</a> is an API developed by Nvidia for interfacing with GPUs. PyTorch provides us with a layer of abstraction, and allows us to launch CUDA kernels using pure Python.</p>
<p>In short, we get the power of parallelizing our tensor computations on GPUs, whilst only writing (relatively) simple Python!</p>
<p>Here, we define the function <code class="docutils literal notranslate"><span class="pre">set_device</span></code>, which returns the device use in the notebook, i.e., <code class="docutils literal notranslate"><span class="pre">cpu</span></code> or <code class="docutils literal notranslate"><span class="pre">cuda</span></code>. Unless otherwise specified, we use this function on top of every tutorial, and we store the device variable such as</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
<p>Let’s define the function using the PyTorch package <code class="docutils literal notranslate"><span class="pre">torch.cuda</span></code>, which is lazily initialized, so we can always import it, and use <code class="docutils literal notranslate"><span class="pre">is_available()</span></code> to determine if our system supports CUDA.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Set the device. CUDA if available, CPU otherwise</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is not enabled in this notebook. </span><span class="se">\n</span><span class="s2">&quot;</span>
          <span class="s2">&quot;If you want to enable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">&quot;</span>
          <span class="s2">&quot;`Hardware accelerator.` and select `GPU` from the dropdown menu&quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is enabled in this notebook. </span><span class="se">\n</span><span class="s2">&quot;</span>
          <span class="s2">&quot;If you want to disable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">&quot;</span>
          <span class="s2">&quot;`Hardware accelerator.` and select `None` from the dropdown menu&quot;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s make some CUDA tensors!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># common device agnostic way of writing code that can run on cpu OR gpu</span>
<span class="c1"># that we provide for you in each of the tutorials</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>

<span class="c1"># we can specify a device when we first create our tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># we can also use the .to() method to change the device a tensor lives on</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y before calling to() | device: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> | dtype: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y after calling to() | device: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> | dtype: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU is enabled in this notebook. 
If you want to disable it, in the menu under `Runtime` -&gt; 
`Hardware accelerator.` and select `None` from the dropdown menu
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.float32
cuda:0
y before calling to() | device: cpu | dtype: torch.FloatTensor
y after calling to() | device: cuda:0 | dtype: torch.cuda.FloatTensor
</pre></div>
</div>
</div>
</div>
<p><strong>Operations between cpu tensors and cuda tensors</strong></p>
<p>Note that the type of the tensor changed after calling <code class="docutils literal notranslate"><span class="pre">.to()</span></code>. What happens if we try and perform operations on tensors on devices?</p>
<p>We cannot combine CUDA tensors and CPU tensors in this fashion. If we want to compute an operation that combines tensors on different devices, we need to move them first! We can use the <code class="docutils literal notranslate"><span class="pre">.to()</span></code> method as before, or the <code class="docutils literal notranslate"><span class="pre">.cpu()</span></code> and <code class="docutils literal notranslate"><span class="pre">.cuda()</span></code> methods. Note that using the <code class="docutils literal notranslate"><span class="pre">.cuda()</span></code> will throw an error, if CUDA is not enabled in your machine.</p>
<p>Generally, in this course, all Deep Learning is done on the GPU, and any computation is done on the CPU, so sometimes we have to pass things back and forth, so you’ll see us call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># moving to cpu</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># alternatively, you can use x = x.cpu()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># moving to gpu</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>  <span class="c1"># alternatively, you can use y = y.cuda()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([3, 5, 7])
tensor([ 9, 11, 13], device=&#39;cuda:0&#39;)
</pre></div>
</div>
</div>
</div>
<p><strong>Acknowledgements</strong></p>
<p>Code adopted from the Deep Learning Summer School offered by Neuromatch Academy</p>
<p><a class="reference external" href="https://deeplearning.neuromatch.io/tutorials/intro.html">https://deeplearning.neuromatch.io/tutorials/intro.html</a></p>
</section>
</section>
</section>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"eacc1f703dba48c5857bf1a55e50ed77": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2918dffb7eb248bb8c8af1ac357a4d8e": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_eacc1f703dba48c5857bf1a55e50ed77", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=47d0M3UAXNc\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7ff244aea4d0>", "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/47d0M3UAXNc?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/Week_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Week_4.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Week 4</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Week_4_Lecture_2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 2: Neural Networks: A Review Part 2 <sup><mark style="background-color:gold">Code</mark> </sup></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Dr Vineeth N Balasubramanian<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>